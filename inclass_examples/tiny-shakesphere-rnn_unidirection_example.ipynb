{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "556c059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97045a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2fc1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since tiny_shakespeare couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/bransonboggia/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e (last modified on Fri Feb 13 12:10:22 2026).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Chars. in dataset:  1003854\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tiny_shakespeare')\n",
    "text = dataset['train']['text'][0]\n",
    "\n",
    "print(\"Num Chars. in dataset: \", len(text))\n",
    "# print(\"Data: \\n\", text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad41aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_encode = {ch: i for i, ch in enumerate(chars)}\n",
    "rev_char_encode = {i: ch for ch, i in char_encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e288fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape:  tensor(18)\n"
     ]
    }
   ],
   "source": [
    "fall_back = char_encode.get(\" \", 0)\n",
    "\n",
    "def encode(s: str) -> torch.tensor:\n",
    "    return torch.tensor([char_encode.get(ch, fall_back) for ch in s], dtype=torch.long)\n",
    "    \n",
    "def decode(ids) -> str:\n",
    "    return \"\".join([rev_char_encode[int(i)] for i in ids])\n",
    "\n",
    "data = encode(text)\n",
    "print(\"Encoded data shape: \", data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc21f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903468 50193 50193\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "\n",
    "train_end = int(0.9 * N)\n",
    "val_end = int(0.95 * N)\n",
    "\n",
    "train_ids = data[:train_end]\n",
    "val_ids = data[train_end:val_end]\n",
    "test_ids = data[val_end:]\n",
    "\n",
    "print(len(train_ids), len(val_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0e047a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(data: torch.Tensor, batch_size: int) -> torch.Tensor:\n",
    "    n_batches = data.size(0) // batch_size\n",
    "    data = data[:n_batches * batch_size]\n",
    "    return data.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23fae22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14116])\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "eval_batch_size = 256\n",
    "\n",
    "train_data = batch(train_ids, train_batch_size).to(device)\n",
    "val_data = batch(val_ids, eval_batch_size).to(device)\n",
    "test_data = batch(test_ids, eval_batch_size).to(device)\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c5156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data: torch.Tensor, i: int, seq_len: int):\n",
    "    seq_len = min(seq_len, data.size(1) - 1 - i)\n",
    "    X = data[:, i:i+seq_len]\n",
    "    Y = data[:, i+1:i+seq_len+1]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acfcb79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (embedding): Embedding(65, 128)\n",
      "  (rnn): RNN(128, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=65, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int = 128,\n",
    "        hidden_size: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.2,\n",
    "        nonlinearity: str = \"tanh\", \n",
    "        bidirectional: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            nonlinearity=nonlinearity,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * self.num_directions, vocab_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        embed = self.embedding(x)\n",
    "        out, h = self.rnn(embed, h)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.fc(out)\n",
    "        return logits, h\n",
    "\n",
    "model = CharRNN(vocab_size=vocab_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "271ec2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 32]) logits: torch.Size([64, 32, 65]) hidden: torch.Size([2, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "X_tmp, Y_tmp = get_batch(train_data, 0, seq_len=32)\n",
    "h_tmp = model.init_hidden(batch_size=X_tmp.size(0), device=device)\n",
    "logits_tmp, h_tmp2 = model(X_tmp, h_tmp)\n",
    "print(\"X:\", X_tmp.shape, \"logits:\", logits_tmp.shape, \"hidden:\", h_tmp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85b2301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f7c2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data, optim, loss_fn, seq_len=128, clip_grad=1.0):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    h = model.init_hidden(data.size(0), device)\n",
    "    \n",
    "    # THERE WAS AN ERROR HERE CAUSING PROBLEMS, MAKE SURE YOU FIX IT IN YOUR CODE.\n",
    "    # WAS CAUSING TRAINING DEGREDATION BECAUSE IT WAS ONLY DOING 1 UPDATE/EPOCH\n",
    "    # HAS THE WRONG DIMENSIONS, WAS: `data.size(0) - 1`, SHOULD BE data.size(1) - 1\n",
    "    for i in range(0, data.size(1) - 1, seq_len):\n",
    "        X, Y = get_batch(data, i, seq_len)\n",
    "        \n",
    "        logits, h = model(X, h)\n",
    "        \n",
    "        h = h.detach()\n",
    "        \n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, model.vocab_size),\n",
    "            Y.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        n_tokens = Y.numel()\n",
    "        \n",
    "        total_loss += loss.item() * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "        \n",
    "    return total_loss / total_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86e78788",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def eval(model, data, loss_fn, device, seq_len=128):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    h = model.init_hidden(batch_size=data.size(0), device=device)\n",
    "\n",
    "    for i in range(0, data.size(1) - 1, seq_len):\n",
    "        X, Y = get_batch(data, i, seq_len)\n",
    "        logits, h = model(X, h)\n",
    "        \n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, model.vocab_size),\n",
    "            Y.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        n_tokens = Y.numel()\n",
    "        total_loss += loss.item() * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c345761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:05<04:15,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 2.6939 (ppl 14.79) | val loss 2.2843 (ppl 9.82)\n",
      "  Saved new best checkpoint (val loss 2.2843)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:10<04:12,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train loss 2.1490 (ppl 8.58) | val loss 2.0567 (ppl 7.82)\n",
      "  Saved new best checkpoint (val loss 2.0567)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:15<04:07,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train loss 1.9906 (ppl 7.32) | val loss 1.9356 (ppl 6.93)\n",
      "  Saved new best checkpoint (val loss 1.9356)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:21<04:02,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train loss 1.8957 (ppl 6.66) | val loss 1.8550 (ppl 6.39)\n",
      "  Saved new best checkpoint (val loss 1.8550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:26<03:56,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train loss 1.8303 (ppl 6.24) | val loss 1.7923 (ppl 6.00)\n",
      "  Saved new best checkpoint (val loss 1.7923)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:31<03:50,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train loss 1.7830 (ppl 5.95) | val loss 1.7468 (ppl 5.74)\n",
      "  Saved new best checkpoint (val loss 1.7468)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:36<03:45,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train loss 1.7450 (ppl 5.73) | val loss 1.7069 (ppl 5.51)\n",
      "  Saved new best checkpoint (val loss 1.7069)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:41<03:39,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train loss 1.7159 (ppl 5.56) | val loss 1.6794 (ppl 5.36)\n",
      "  Saved new best checkpoint (val loss 1.6794)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:47<03:34,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train loss 1.6919 (ppl 5.43) | val loss 1.6558 (ppl 5.24)\n",
      "  Saved new best checkpoint (val loss 1.6558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:52<03:29,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss 1.6714 (ppl 5.32) | val loss 1.6331 (ppl 5.12)\n",
      "  Saved new best checkpoint (val loss 1.6331)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:57<03:23,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss 1.6549 (ppl 5.23) | val loss 1.6171 (ppl 5.04)\n",
      "  Saved new best checkpoint (val loss 1.6171)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [01:02<03:18,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss 1.6384 (ppl 5.15) | val loss 1.6053 (ppl 4.98)\n",
      "  Saved new best checkpoint (val loss 1.6053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [01:08<03:13,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss 1.6254 (ppl 5.08) | val loss 1.5906 (ppl 4.91)\n",
      "  Saved new best checkpoint (val loss 1.5906)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:13<03:07,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss 1.6148 (ppl 5.03) | val loss 1.5833 (ppl 4.87)\n",
      "  Saved new best checkpoint (val loss 1.5833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:18<03:02,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss 1.6034 (ppl 4.97) | val loss 1.5735 (ppl 4.82)\n",
      "  Saved new best checkpoint (val loss 1.5735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [01:23<02:56,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss 1.5935 (ppl 4.92) | val loss 1.5637 (ppl 4.78)\n",
      "  Saved new best checkpoint (val loss 1.5637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:28<02:51,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss 1.5835 (ppl 4.87) | val loss 1.5549 (ppl 4.73)\n",
      "  Saved new best checkpoint (val loss 1.5549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [01:34<02:45,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss 1.5775 (ppl 4.84) | val loss 1.5503 (ppl 4.71)\n",
      "  Saved new best checkpoint (val loss 1.5503)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [01:39<02:41,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss 1.5694 (ppl 4.80) | val loss 1.5473 (ppl 4.70)\n",
      "  Saved new best checkpoint (val loss 1.5473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:44<02:36,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss 1.5633 (ppl 4.77) | val loss 1.5412 (ppl 4.67)\n",
      "  Saved new best checkpoint (val loss 1.5412)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:49<02:31,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train loss 1.5572 (ppl 4.75) | val loss 1.5338 (ppl 4.64)\n",
      "  Saved new best checkpoint (val loss 1.5338)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [01:55<02:26,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train loss 1.5512 (ppl 4.72) | val loss 1.5301 (ppl 4.62)\n",
      "  Saved new best checkpoint (val loss 1.5301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [02:00<02:20,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train loss 1.5452 (ppl 4.69) | val loss 1.5235 (ppl 4.59)\n",
      "  Saved new best checkpoint (val loss 1.5235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [02:05<02:15,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | train loss 1.5401 (ppl 4.66) | val loss 1.5224 (ppl 4.58)\n",
      "  Saved new best checkpoint (val loss 1.5224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [02:10<02:10,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | train loss 1.5350 (ppl 4.64) | val loss 1.5163 (ppl 4.56)\n",
      "  Saved new best checkpoint (val loss 1.5163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [02:15<02:05,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | train loss 1.5311 (ppl 4.62) | val loss 1.5150 (ppl 4.55)\n",
      "  Saved new best checkpoint (val loss 1.5150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [02:21<01:59,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | train loss 1.5271 (ppl 4.60) | val loss 1.5115 (ppl 4.53)\n",
      "  Saved new best checkpoint (val loss 1.5115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [02:26<01:54,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | train loss 1.5235 (ppl 4.59) | val loss 1.5076 (ppl 4.52)\n",
      "  Saved new best checkpoint (val loss 1.5076)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [02:31<01:49,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | train loss 1.5190 (ppl 4.57) | val loss 1.5086 (ppl 4.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [02:36<01:44,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | train loss 1.5156 (ppl 4.55) | val loss 1.5057 (ppl 4.51)\n",
      "  Saved new best checkpoint (val loss 1.5057)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [02:42<01:39,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | train loss 1.5120 (ppl 4.54) | val loss 1.5005 (ppl 4.48)\n",
      "  Saved new best checkpoint (val loss 1.5005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [02:47<01:34,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | train loss 1.5082 (ppl 4.52) | val loss 1.5011 (ppl 4.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [02:52<01:28,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | train loss 1.5055 (ppl 4.51) | val loss 1.4990 (ppl 4.48)\n",
      "  Saved new best checkpoint (val loss 1.4990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [02:57<01:23,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | train loss 1.5028 (ppl 4.49) | val loss 1.4997 (ppl 4.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [03:02<01:18,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | train loss 1.4999 (ppl 4.48) | val loss 1.4983 (ppl 4.47)\n",
      "  Saved new best checkpoint (val loss 1.4983)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [03:08<01:12,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | train loss 1.4975 (ppl 4.47) | val loss 1.4951 (ppl 4.46)\n",
      "  Saved new best checkpoint (val loss 1.4951)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [03:13<01:07,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | train loss 1.4960 (ppl 4.46) | val loss 1.4935 (ppl 4.45)\n",
      "  Saved new best checkpoint (val loss 1.4935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [03:18<01:02,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | train loss 1.4926 (ppl 4.45) | val loss 1.4918 (ppl 4.44)\n",
      "  Saved new best checkpoint (val loss 1.4918)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [03:23<00:57,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | train loss 1.4891 (ppl 4.43) | val loss 1.4903 (ppl 4.44)\n",
      "  Saved new best checkpoint (val loss 1.4903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [03:28<00:51,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | train loss 1.4871 (ppl 4.42) | val loss 1.4902 (ppl 4.44)\n",
      "  Saved new best checkpoint (val loss 1.4902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [03:33<00:46,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | train loss 1.4846 (ppl 4.41) | val loss 1.4866 (ppl 4.42)\n",
      "  Saved new best checkpoint (val loss 1.4866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [03:39<00:41,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | train loss 1.4822 (ppl 4.40) | val loss 1.4880 (ppl 4.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [03:44<00:36,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | train loss 1.4814 (ppl 4.40) | val loss 1.4903 (ppl 4.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [03:49<00:31,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | train loss 1.4793 (ppl 4.39) | val loss 1.4849 (ppl 4.41)\n",
      "  Saved new best checkpoint (val loss 1.4849)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [03:54<00:26,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | train loss 1.4754 (ppl 4.37) | val loss 1.4914 (ppl 4.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [04:00<00:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | train loss 1.4757 (ppl 4.37) | val loss 1.4874 (ppl 4.43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [04:05<00:15,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | train loss 1.4733 (ppl 4.36) | val loss 1.4858 (ppl 4.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [04:10<00:10,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | train loss 1.4710 (ppl 4.35) | val loss 1.4847 (ppl 4.41)\n",
      "  Saved new best checkpoint (val loss 1.4847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [04:16<00:05,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | train loss 1.4693 (ppl 4.35) | val loss 1.4817 (ppl 4.40)\n",
      "  Saved new best checkpoint (val loss 1.4817)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:21<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | train loss 1.4678 (ppl 4.34) | val loss 1.4816 (ppl 4.40)\n",
      "  Saved new best checkpoint (val loss 1.4816)\n",
      "Training time: 261.65s on mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "seq_len = 256\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    train_loss = train_one_epoch(model, train_data, optim, loss_fn, seq_len=seq_len, clip_grad=1.0)\n",
    "    val_loss = eval(model, val_data, loss_fn, device, seq_len=seq_len)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"train loss {train_loss:.4f} (ppl {math.exp(train_loss):.2f}) | \"\n",
    "        f\"val loss {val_loss:.4f} (ppl {math.exp(val_loss):.2f})\"\n",
    "    )\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        ckpt = {\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"char_encode\": char_encode,\n",
    "            \"rev_char_encode\": rev_char_encode,\n",
    "            \"config\": {\n",
    "                \"vocab_size\": vocab_size,\n",
    "                \"emb_dim\": model.embedding.embedding_dim,\n",
    "                \"hidden_size\": model.hidden_size,\n",
    "                \"num_layers\": model.num_layers,\n",
    "                \"dropout\": model.dropout.p,\n",
    "                \"nonlinearity\": model.rnn.nonlinearity,\n",
    "            }\n",
    "        }\n",
    "        torch.save(ckpt, \"char_rnn_best.pt\")\n",
    "        print(f\"  Saved new best checkpoint (val loss {best_val_loss:.4f})\")\n",
    "\n",
    "end = timer()\n",
    "print(f\"Training time: {end - start:.2f}s on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d3ba340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.6282 | Test ppl: 5.09\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"char_rnn_best.pt\", map_location=device)\n",
    "\n",
    "model = CharRNN(**ckpt[\"config\"]).to(device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "stoi = ckpt[\"char_encode\"]\n",
    "itos = ckpt[\"rev_char_encode\"]\n",
    "\n",
    "test_loss = eval(model, test_data, loss_fn, device, seq_len=seq_len)\n",
    "print(f\"Test loss: {test_loss:.4f} | Test ppl: {math.exp(test_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d12272",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_text(\n",
    "    model,\n",
    "    prompt: str,\n",
    "    length: int = 500,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int | None = None,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    fallback_id = stoi.get(\" \", 0)\n",
    "\n",
    "    prompt_ids = torch.tensor(\n",
    "        [stoi.get(ch, fallback_id) for ch in prompt],\n",
    "        dtype=torch.long,\n",
    "        device=device\n",
    "    ).unsqueeze(0)  \n",
    "\n",
    "    h = model.init_hidden(batch_size=1, device=device)\n",
    "\n",
    "    logits, h = model(prompt_ids, h)\n",
    "\n",
    "    next_logits = logits[:, -1, :]\n",
    "    generated = list(prompt)\n",
    "\n",
    "    for _ in range(length):\n",
    "        scaled = next_logits / max(temperature, 1e-6)\n",
    "\n",
    "        if top_k is not None:\n",
    "            topk_vals, topk_idx = torch.topk(scaled, k=top_k, dim=-1)\n",
    "            filtered = torch.full_like(scaled, float(\"-inf\"))\n",
    "            filtered.scatter_(1, topk_idx, topk_vals)\n",
    "            scaled = filtered\n",
    "\n",
    "        probs = F.softmax(scaled, dim=-1)        \n",
    "        next_id = torch.multinomial(probs, 1)    \n",
    "        next_char = itos[int(next_id.item())]\n",
    "        generated.append(next_char)\n",
    "\n",
    "        logits, h = model(next_id, h)             \n",
    "        next_logits = logits[:, -1, :]            \n",
    "\n",
    "    return \"\".join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5acd087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Now may you may burnt another bed:\n",
      "What nor dislimmed, of the right is broke.\n",
      "Bey that will be seing a stame is Romeo!\n",
      "\n",
      "GLOUCESTER:\n",
      "Let I for your hands.\n",
      "\n",
      "CORIOLANUS:\n",
      "Now, that is the wind!\n",
      "\n",
      "KING RICHARD III:\n",
      "Good primes\n",
      "Sir, bisalishness bolels call it!\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Ay, thou entagual! what fas leave it best of a leave,\n",
      "Is in the shame?\n",
      "\n",
      "JULIET:\n",
      "What, kinchers. You stour my what a wife, come of the light\n",
      "And sarth at any wrong, tell war; then I she would.\n",
      "\n",
      "KING CIWIS:\n",
      "Look on the command to have you:\n",
      "my supple not,\n",
      "As this as traitor like it with thy grave and regit\n",
      "That are you can conde\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, prompt=\"ROMEO:\\n\", length=600, temperature=0.9, top_k=40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_pythorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
